{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02-DeLeon.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK9sl-FOJLGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LqK8dwpJTl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is used to create a dictionary with the 3000 most common words from the email files. It does this by adding all the words and symbols into the dictionary and then removes all the non-alpha numeric characters, leaving it with the most used words.\n",
        "\n",
        "def make_Dictionary(root_dir):\n",
        "  list_of_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        all_words = line.split()\n",
        "        list_of_words += all_words\n",
        "  dictionary = Counter(list_of_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI7fMJ9sJkao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This functions extracts the feature columns and populates the values. It also analyzes the file names of each email and figures out if it is spam or not based on the name. Afterwards, it uses the function to create the labelled data column. Overall, it extracts the feature dataset, test and training data, and labelled column.\n",
        "\n",
        "def extract_features(mail_dir):\n",
        "  allfiles = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(allfiles),3000))\n",
        "  train_labels = np.zeros(len(allfiles))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in allfiles:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUfF7SKaJmyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "7d963afb-9c3b-474f-bd56-0b8235d81a7e"
      },
      "source": [
        "# This uses the two functions created and runs them. It trains the Gaussian model by using model.fit function and then runs the trained model with the test data set. This will output an accuracy score of the model's performance.\n",
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA_02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA_02/Data/test-mails'\n",
        "\n",
        "new_dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "print (\"Training Model using Gaussian Naive Bayes algorithm...\")\n",
        "model.fit(features_matrix, labels)\n",
        "print (\"Completed Training\")\n",
        "print (\"Testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data, Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naive Bayes algorithm...\n",
            "Completed Training\n",
            "Testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data, Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02-DeLeon.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK9sl-FOJLGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LqK8dwpJTl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function is used to create a dictionary with the 3000 most common words from the email files. It does this by adding all the words and symbols into the dictionary and then removes all the non-alpha numeric characters, leaving it with the most used words.\n",
        "\n",
        "#definining function to get the top 3000 most common words from training data\n",
        "def make_Dictionary(root_dir):\n",
        "# creating an empty list to put the words from the data into\n",
        "  list_of_words = []\n",
        "# extracting all the files into the notebook\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        all_words = line.split()\n",
        "        list_of_words += all_words\n",
        "#counting all the texts in the file and putting it into dictionary variable\n",
        "  dictionary = Counter(list_of_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "#getting rid of items with non-alphabet characters\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "#getting rid of items with single letters\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI7fMJ9sJkao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This functions extracts the feature columns and populates the values. It also analyzes the file names of each email and figures out if it is spam or not based on the name. Afterwards, it uses the function to create the labelled data column. Overall, it extracts the feature dataset, test and training data, and labelled column.\n",
        "\n",
        "#this defines function to create the feature matrix and training labels\n",
        "def extract_features(mail_dir):\n",
        "#this extracts all the file links from folders\n",
        "  allfiles = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "#creates feature matrix with length of 'allfiles'\n",
        "  features_matrix = np.zeros((len(allfiles),3000))\n",
        "#create an array of zeros with the length of 'allfiles'\n",
        "  train_labels = np.zeros(len(allfiles))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in allfiles:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "#splits the words\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "#splits file with \"/\"\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "#marks this file as spam in training label\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels\n",
        "#returns feature matrix where rows are the file numbers and columns are for the 3000 words\n",
        "#returns train_labels which are the final results if these files are spam\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUfF7SKaJmyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "27fa76a9-dc65-4fd7-90d5-afa88021cf13"
      },
      "source": [
        "# This uses the two functions created and runs them. It trains the Gaussian model by using model.fit function and then runs the trained model with the test data set. This will output an accuracy score of the model's performance.\n",
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA_02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA_02/Data/test-mails'\n",
        "\n",
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
        "\n",
        "#uses Gaussian model\n",
        "model = GaussianNB()\n",
        "\n",
        "print (\"Training Model using Gaussian Naive Bayes algorithm...\")\n",
        "#trains the model\n",
        "model.fit(features_matrix, labels)\n",
        "print (\"Completed Training\")\n",
        "print (\"Testing trained model to predict Test Data labels\")\n",
        "#predicts the models\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data, Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naive Bayes algorithm...\n",
            "Completed Training\n",
            "Testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data, Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}